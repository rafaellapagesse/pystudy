{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python #\n",
    "\n",
    "## - Pacote NETCDF4 - ##\n",
    "\n",
    "### 0) Referências: ###\n",
    "\n",
    "\n",
    "- http://unidata.github.io/netcdf4-python/#section1\n",
    "- http://unidata.github.io/netcdf4-python/#netCDF4.Dataset\n",
    "- https://netcdf4-python.googlecode.com/svn/trunk/docs/netCDF4-module.html\n",
    "\n",
    "\n",
    "É uma biblioteca do Python com a qual é possível criar, ler e alterar arquivos no formato netcdf. \n",
    "\n",
    "Pacotes Requeridos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**%matplorlib inline** , serve para mostrar logo após a célula de código, o resultado gerado a partir dela.\n",
    "### 1) Criando / Abrindo / Fechando um arquivo netCDF: ###\n",
    "\n",
    "   No pacote netCDF4 existe o construtor (classe) chamado **Dataset**. Ele é utilizado para abrir, ler e alterar arquivos. O Dataset de um arquivo netCDF contém informações em dimensões, variáveis, grupos e atributos. Juntos eles descrevem o significado dos dados e as relações entre os dados armazenados no arquivo netCDF. Arquivos netCDF vêm em 5 formatos; **NETCDF3_CLASSIC, NETCDF3_64BIT_OFFSET, NETCDF3_64BIT_DATA, NETCDF4_CLASSIC,** e **NETCDF4**.   \n",
    "   O modulo netCDF4 pode ler e alterar arquivos em qualquer um desses formatos. Quando criar um novo arquivo, o formato pode ser especificado usando a keyword **format** do Dataset. O formato padrão é o NETCDF4. Para ver qual é o formato de um dado arquivo, você pode usar o atributo __data_model__. Para fechar o arquivo netCDF, use o método close do Dataset.\n",
    "   \n",
    "   Segue um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arquivo = nc.Dataset(\"brleste_oc_20160303.nc\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(arquivo.data_model)\n",
    "arquivo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que por causa da linha '<code> arquivo.close()</code>', quando essa célula for rodada novamente ocorrerá um erro e será necessário abrir novamente o arquivo pela célula acima para então conseguir o formato do netCDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Keywords do Dataset - ####\n",
    "def __init__(\tself, filename, mode=\"r\", clobber=True, diskless=False, persist=False, weakref=False, format='NETCDF4')\n",
    "\n",
    "Analisando item a item, temos que:\n",
    "\n",
    " 1. **filename**: nome do arquivo que contém o Dataset.\n",
    " \n",
    " 2. **mode**: é o modo de acesso, que pode ser: \n",
    "\n",
    " **r** : significa somente ler. Nenhum dado pode ser alterado.\n",
    " \n",
    " **w** : significa _write_ , escrever. Ele cria um novo arquivo e o arquivo com o mesmo nome é deletado.\n",
    " \n",
    " **a** ou **r+** : significa _append_; O arquivo existente é aberto para ser lido e alterado.\n",
    "  \n",
    " 3. **clobber**: Se estiver **True**(default), ao abrir um arquivo com o modo 'w' irá sobrepujar um arquivo existente com o mesmo nome. Caso esteja **False**, uma exceção será se o arquivo com o mesmo nome existir.\n",
    " \n",
    " _clobber definition (eng): to defeat someone very easily in a way that is embarrassing for the team that loses._ \n",
    "  \n",
    " 5. **diskless**: caso **\"True\"**, cria um arquivo na memória ao invés do disco rígido.\n",
    "  \n",
    " 6. **persist**: se **\"diskless=True\"**, mantém o arquivo no disco quando ele é fechado. (default **False**)\n",
    "\n",
    " 4. **format**: é o formato do arquivo netCDF( um deles: 'NETCDF4', 'NETCDF4_CLASSIC', 'NETCDF3_CLASSIC', 'NETCDF3_64BIT_OFFSET' ou 'NETCDF3_64BIT_DATA'). Só é relevante quando estiver no modo \"**w**\", caso contrário, o formato é automaticamente detectado.\n",
    "  \n",
    " 7. **keepweakref**: if True, child Dimension and Variable instances will keep weak references to the parent Dataset or Group object. Default is False, which means strong references will be kept. Having Dimension and Variable instances keep a strong reference to the parent Dataset instance, which in turn keeps a reference to child Dimension and Variable instances, creates circular references. Circular references complicate garbage collection, which may mean increased memory usage for programs that create may Dataset instances with lots of Variables. Setting keepweakref=True allows Dataset instances to be garbage collected as soon as they go out of scope, potential reducing memory usage. However, in most cases this is not desirable, since the associated Variable instances may still be needed, but are rendered unusable when the parent Dataset instance is garbage collected.\n",
    " \n",
    " #### - Variáveis do Dataset -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **data_model**: describes the netCDF data model version, one of NETCDF3_CLASSIC, NETCDF4, NETCDF4_CLASSIC, NETCDF3_64BIT_OFFSET or NETCDF3_64BIT_DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (arquivo.data_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **dimensions**: The dimensions dictionary maps the names of dimensions defined for the Group or Dataset to instances of the Dimension class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(arquivo.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **variables**: The variables dictionary maps the names of variables defined for this Dataset or Group to instances of the Variable class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (arquivo.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **groups**: The groups dictionary maps the names of groups created for this Dataset or Group to instances of the Group class (the Dataset class is simply a special case of the Group class which describes the root group in the netCDF4 file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (arquivo.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **vltypes**: The vltypes dictionary maps the names of variable-length types defined for the Group or Dataset to instances of the VLType class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (arquivo.vltypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **path**: path shows the location of the Group in the Dataset in a unix directory format (the names of groups in the hierarchy separated by backslashes). A Dataset instance is the root group, so the path is simply '/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (arquivo.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **parent**: parent is a reference to the parent Group instance. None for the root group or Dataset instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (arquivo.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **disk_format**: disk_format describes the underlying file format, one of NETCDF3, HDF5, HDF4, PNETCDF, DAP2, DAP4 or UNDEFINED. Only available if using netcdf C library version >= 4.3.1, otherwise will always return UNDEFINED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(arquivo.disk_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **enumtypes**: The enumtypes dictionary maps the names of Enum types defined for the Group or Dataset to instances of the EnumType class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (arquivo.enumtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **cmptypes**: The cmptypes dictionary maps the names of compound types defined for the Group or Dataset to instances of the CompoundType class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(arquivo.cmptypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2) Grupos em um arquivo netCDF ###\n",
    "\n",
    "Os grupos em um netCDF (na versão 4) funcionam como diretórios no Sistema Operacional (SO). Os grupos servem como containers para variáveis, dimensões e atributos, assim como outros grupos. O Dataset cria um grupo especial, chamado 'root group', que é similar ao diretório raiz em um sistema operacional. \n",
    "\n",
    "Para criar um grupo, use o método <code> createGroup </code> do Dataset. O <code> createGroup </code> requer um único argumento, uma  string do python contendo o nome do novo grupo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootgrp = nc.Dataset(\"teste.nc\", \"w\", format='NETCDF4')\n",
    "rootgrp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootgrp = nc.Dataset(\"teste.nc\",\"a\")\n",
    "fcastgrp = rootgrp.createGroup(\"forecasts\")\n",
    "analgrp = rootgrp.createGroup(\"analyses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rootgrp.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupos podem existir dentro de grupos em um Dataset, como pastas existem dentro de pastas. Cada instância tem um atributo **<code>groups</code>** contendo todos os grupos que se encontram dentro daquele grupo.\n",
    "\n",
    "Cada instância de um grupo também tem um atributo **<code> path </code>** que contém uma espécie de path de um diretório unix para esse grupo. \n",
    "\n",
    "Observe o exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fcastgrp1 = rootgrp.createGroup(\"/forecasts/model1\")\n",
    "fcastgrp2 = rootgrp.createGroup(\"/forecasts/model2\")\n",
    "print(rootgrp.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Obs.: **Note que o atributo <code> groups </code> agora contém os crupos criados dentro de /forecast.     \n",
    "<code>      \n",
    "        OrderedDict([('forecasts', <class 'netCDF4._netCDF4.Group'>\n",
    "        group /forecasts:\n",
    "            dimensions(sizes): \n",
    "            variables(dimensions): \n",
    "            groups: model1, model2)\n",
    "        \n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootgrp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Dimensões em um arquivo netCDF ###\n",
    "\n",
    "netCDF define os tamanhos de todas as variáveis em termos de dimensões, então antes de qualquer variável ser criada as dimensões que elas usam devem ser  criadas antes. Um caso especial, pouco usado na prática, é o de uma variável escalar, que não tem dimensão.\n",
    "\n",
    "Uma dimensão é criada usando o método <code> createDimension</code> do Dataset ou Grupo. Uma string do Python é usada para atribuir o nome da dimensão e um numero inteiro é usado para atribuir o tamanho. Para criar uma dimensão ilimitada (uma dimensão que possa ser adicionada - _appended to_), o valor do tamanho é configurado como <code> None </code> ou <code> 0 </code>.\n",
    "\n",
    "Neste exemplo, tanto as dimensões **<code>time</code>** e **<code>level</code>** são ilimitadas. Ter mais de uma dimensão ilimitada é uma característica do netCDF4, nos arquivos netCDF3 só poderia haver uma, e ela deveria ser a primeira dimensão da variável.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootgrp = nc.Dataset(\"teste.nc\",\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "level = rootgrp.createDimension(\"level\", None)\n",
    "time = rootgrp.createDimension(\"time\",None)\n",
    "lat = rootgrp.createDimension(\"latitude\", 73)\n",
    "lon = rootgrp.createDimension(\"longitude\",144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as dimensões foram armazenadas em um dicionário python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rootgrp.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a função <code>len</code> com uma dimensão retorna o tamanho atual daquela dimensão. O método <code>isunlimited</code> de uma dimensão pode ser usado para determinar se a dimensão é ilimitada, ou _appendable_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-12c8e69343d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lon' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(lat.isunlimited())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(time.isunlimited())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Printar\" o <code>Dimension object</code> (dimobj) fornece informação resumida, incluindo o nome e o tamanho da dimensão, além de informar se são ilimitadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dimobj in rootgrp.dimensions.values():\n",
    "    print(dimobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nome de Dimensões pode ser alterado usando o método **<code>netCDF4.Datatset.renameDimension</code>** de um Dataset ou Group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Variáveis em um arquivo netCDF ###\n",
    "\n",
    "Variáveis do netcdf se comportam como um array multidimensionais de objetos do python, fornecido pelo módulo numpy. Entretanto, diferentemente dos arrays do numpy, as variáveis do netcdf4 podem ser _appended_ a uma ou mais dimensões 'ilimitadas'.\n",
    "Para criar uma variável netCDF, use o método **<code>createVariable</code>** do Dataset ou Grupo. Este método tem dois argumentos mandatórios,o nome da variável (uma string), e o datatype da variável. A dimensão da variável é dada por uma tupla contendo os nomes das dimensões (definidas previamente com o **<code>createDimension</code>**). Para criar uma variável escalar, \n",
    "simplismente deixe de lado a keyword dimensions. \n",
    "\n",
    "Os datatypes primitivos da variável correspondem ao atributo dtype de um array do numpy. Você pode especificar o datatype como um objeto dtype do numpy, ou qualquer coisa que possa ser convertida para um objeto dtype do numpy. Os especificadores de datatype incluem: 'f4' (32-bit floating point), 'f8' (64-bit floating point), 'i4' (32-bit signed integer), 'i2' (16-bit signed integer), 'i8' (64-bit singed integer), 'i1' (8-bit signed integer), 'u1' (8-bit unsigned integer), 'u2' (16-bit unsigned integer), 'u4' (32-bit unsigned integer), 'u8' (64-bit unsigned integer), ou 'S1' (single-character string).\n",
    "\n",
    "Os typecodes antigos com um caracter unico ('f','d','h', 's','b','B','c','i','l'), correspondendo a ('f4','f8','i2','i2','i1','i1','S1','i4','i4'), também vão funcionar. Os tipos 'unsigned interger' e '64-bit interger' só podem ser usados se o formato do arquivo for NETCDF4. \n",
    "\n",
    "As dimensões por si só são geralmente definidas como variáveis, chamadas de variáveis coordenadas. O método **<code>createVariable</code>** retorna uma instancia da classe Variable cujos métodos podem ser usados mais tarde para acessar e configurar os dados da variável e seus atributos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times = rootgrp.createVariable(\"time\",\"f8\",(\"time\",))                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "levels = rootgrp.createVariable(\"level\", \"i4\",(\"level\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latitudes = rootgrp.createVariable(\"latitude\",\"f4\",(\"latitude\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "longitudes = rootgrp.createVariable(\"longitude\",\"f4\",(\"longitude\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = rootgrp.createVariable(\"temp\",\"f4\",(\"time\",\"level\",\"latitude\",\"longitude\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ter um resumo da variável numa sessão interativa, basta <code>print(var)</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um caminho pode ser usado para criar uma Variavel dentro de uma hierarquia de grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ftemp = rootgrp.createVariable(\"/forecasts/model1/temp\",\"f4\",(\"time\",\"level\",\"latitude\",\"longitude\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso algum dos grupos não tenha sido criado até o momento, ele será assim o comando for dado.\n",
    "\n",
    "Você também pode questionar sobre um Dataset ou Grupo diretamente para obter as suas instancias usando caminhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rootgrp[\"/forecasts/model1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rootgrp[\"/forecasts/model1/temp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis no Dataset ou em um Grupo são armazenadas em um dicionário, da mesma forma que as dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rootgrp.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nome das variáveis pode ser alterado utilizando o método **<code>renameVariable</code>** de um Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5) Atributos de um arquivo netCDF\n",
    "\n",
    "Há dois tipos de atributos em arquivo netCDF, global e variable. Atributos globais fornecem informações sobre um grupo, ou um dataset como um todo. Atributos de variável fornecem informações sobre uma das variáveis em um grupo.\n",
    "\n",
    "Atributos global são configurados ao designar valores para as variáveis de um Dataset ou Grupo. Atributos variable são configurados ao designar valores as variáveis de variáveis. Atributos podem ser strings, numeros ou sequencias. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "rootgrp.description = \"bogus example script\"\n",
    "rootgrp.history = \"Created \" + time.ctime(time.time())\n",
    "rootgrp.source = \"netCDF4 python module tutorial\"\n",
    "latitudes.units = \"degrees north\"\n",
    "longitudes.units = \"degrees east\"\n",
    "levels.units = \"hPa\"\n",
    "temp.units = \"K\"\n",
    "times.units = \"hours since 0001-01-01 00:00:00.0\"\n",
    "times.calendar = \"gregorian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método <code>ncattrs</code> de um Dataset, Grupo ou Variável pode ser usado para recuperar os nomes de todos os atributos do netCDF. Este método é tido como conveniente, já que usando a função embutida do Python <code>dir</code> irá retornar um amontoado de métodos privados e atributos que não podem (ou não devem) ser modificados pelo usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name in rootgrp.ncattrs():\n",
    "    print(\"Global attr\", name, \"=\", getattr(rootgrp,name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O atributo **<code>\\__dict__</code>** de um Dataset, Grupo ou Variável fornece todos os pares de atributos nome/valor em um dicionário Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (rootgrp.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos podem ser deletados de um Dataset, Grupo ou Variável de um arquivo netCDF usando a declaração do python <code>del</code>. \n",
    "\n",
    "**<code>>>> del grp.foo </code>** \n",
    "\n",
    "O comando acima irá remover o atributo foo do grupo grp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Adicionando dados a um arquivo e acessando dados de um arquivo netCDF\n",
    "\n",
    "Agora que você tem a Variavel netCDF, como acrescentar dados a ela?  Você pode simplismente tratá-la como um array e adicionar dados a ela.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lats = numpy.arange(-90,91,2.5)\n",
    "lons = numpy.arange(-180,180,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(numpy.arange)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "latitudes[:] = lats\n",
    "longitudes[:] = lons\n",
    "\n",
    "print (\"latitudes =\\n\", latitudes[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentemente dos Arrays de objetos do Numpy, variáveis com dimensões ilimitadas vão crescer ao longo dessas dimensões se dados forem alocados além da _range_ de indices definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlats = len(rootgrp.dimensions[\"latitude\"])\n",
    "nlons = len(rootgrp.dimensions[\"longitude\"])\n",
    "print(\"temp shape antes de adicionar dados = \", temp.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso tenha alguma dúvida sobre a função uniform, utilize a função <code>help(uniform)</code> na célula abaixo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(uniform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp[0:5,0:10,:,:] = uniform(size=(5,10,nlats,nlons))\n",
    "print(\"temp shape depois de adicionar dados = \", temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dimensão levels aumentou,  mas nenhum dado foi alocado a variavel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"levels shape depois de adicionar dados de pressão = \", levels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o tamanho da variavel levels aumentou quando dados foram acrescidos ao longo da dimensão level da variavel temp, mesmo nenhum dado tendo sido adicionado a levels.\n",
    "Agora, vamos alocar dados a variavel dimensão levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "levels[:] = [1000.,850.,700.,500.,300.,250.,200.,150.,100.,50.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contudo, há algumas diferenças entre as regras de fatiar(_slice_) de variáveis do NumPy e netCDF. _Slices_ funcionam como sempre, sendo especificado o tripé inínio:fim:intervalo(como feito para <code>lats = numpy.arange(-90,91,2.5)</code>). Ao usar o interger scalar index, **i** pega o **i**ésimo elemento e reduz a posição do output do array em um. Array Booleana e sequência de inteiros se comportam de forma diferente para variáveis netCDF e arrays do numpy. Somente arrays booleanos 1-d e sequencias de inteiros são permitidos, e estes indices funcionam independentemente ao longo de cada dimensão (similar a forma de vetores subscripts no fortran). Isto significa que\n",
    "\n",
    "\n",
    "**<code>>>>temp[0, 0, [0,1,2,3], [0,1,2,3]]\n",
    "</code>**\n",
    "\n",
    "\n",
    "retorna um array de shape (4,4) quando der um _slice_ no arquivo netCDF. Mas para um array do numpy isto retorna um array de shape (4,). De maneira similar, uma variavel netCDF de shape (2,3,4,5) indexada com [0, array([True, False, True]), array([False, True, True, True]),:] retornaria um array (2,3,5). No Numpy, isto retornaria um erro desde que isto seria equivalente a [0, [0,1], [1,2,3], :]. Quando fatiar sequencias de inteiros, os índices não precisam ser ordenados e podem conter duplicatas (ambos são novas características na versão 1.2.1). Mesmo que este comportamento possa causar alguma confusão para os acostumados com as regras de indexação do Numpy, ele fornece uma maneira poderosíssima de extrair dados de uma variavel netCDF multidimensional usando operações lógicas nos arrays de dimensão para criar os *slices*.\n",
    "\n",
    "Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempdat = temp[::2, [1,3,6], lats>0, lons>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<code>tempdat</code> vai extrair os indices 0,2 e 4, níveis de pressão 850, 500 e 200 hPa, todas as latitudes positivas(Hemisfério Norte) e as longitudes positivas (Oriente), resultando num array de shape (3,3,36,71)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-ca25802d9450>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-ca25802d9450>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print\"shape of fancy temp slice =\", tempdat.shape\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print\"shape of fancy temp slice =\", tempdat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para variáveis escalares: Para extrair dados de uma variável escalar v sem dimensão associada, use **<code>np.asarray(v)</code>** ou **<code>\n",
    "v[...]</code>**\n",
    ". O resultado vai ser um array do numpy de escalares. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Lidando com coordenadas de tempo:\n",
    "\n",
    "Valores de coordenadas de tempo se tornam um desafio especial para os usuários de netCDF. A maioria dos padrões de metadados (como CF) especificam que o tempo deve ser medido relativamente a uma data fixa usando um certo calendário, com unidades especificadas como **hours since YY:MM:DD hh-mm-ss**.  Estas unidades podem ser estranhas de se lidar, sem algo para converter os valores para/de datas de calendários. A função chamada **<code>num2date</code>** e **<code>date2num</code>** portam este pacote para fazer justamente isto. Aqui vai um exemplo de como podem ser usados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = [datetime(2001,3,1)+n*timedelta(hours=12) for n in range(temp.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times[:] = date2num (dates,units=times.units,calendar=times.calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"time values (in %s):\" %times.units+\"\\n\",times[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = num2date(times[:],units=times.units,calendar=times.calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"dates corresponding to time values:\\n\",dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<code>num2date</code>** converte valores numéricos de tempo na unidade especificada e calendário para objetos datetime, e **<code>date2num</code>** faz o contrário. Todos os calendários definidos atualmente são aceitos. A função chamada **<code>date2index</code>**  retorna os indices de uma variavel tempo de um arquivo netCDF correnpondendo a uma sequencia de instâncias datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Lendo dados de vários arquivos (MFDataset - Multi File Dataset)\n",
    "\n",
    "Caso você queira ler dados de uma variavel que aparece em vários arquivos netCDF, uma opção a ser usada é a classe **MFDataset** - Multi File Dataset - que lê os dados como se fosse um único arquivo. Ao invés de usar um único filename para criar o Dataset,  crie o MFDataset instance ou com uma lista de filenames, ou com uma string com uma wildcard (que depois é convertida em uma lista ordenada de arquivos usando o modulo [**glob**](https://docs.python.org/2/library/glob.html#module-glob) do Python. Variaveis na lista de arquivos que compartilham a mesma dimensão ilimitada são agregados e podem ser fatiados ao longo de multiplos arquivos. Para ilustrar isso, antes vamos criar um amontoado de aruivos netCDF com a mesma variável (com a mesma dimensão ilimitada). Os arquivos **DEVEM estar nos formatos: \"NETCDF3_64BIT_OFFSET, NETCDF3_64BIT_DATA, NETCDF3_CLASSIC ou NETCDF4_CLASSIC\"** (MF Dataset não suporta arquivos no formato NETCDF4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nf in range(0,10,1):\n",
    "    f = Dataset(\"mftest{}.nc\".format(nf),\"w\", format='NETCDF4_CLASSIC')\n",
    "    f.createDimension(\"x\",0)\n",
    "    x = f.createVariable(\"x\",\"i\",(\"x\",))\n",
    "    x[0:10] = numpy.arange(nf*10,10*(nf+1))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, leia todos os arquivos de uma só vez com o MFDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from netCDF4 import MFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = MFDataset(\"mftest*.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a.variables[\"x\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Compressão eficiente de variáveis em um arquivo netCDF\n",
    "\n",
    "Dados guardados em objetos de uma variavel netCDF podem ser comprimidos e descomprimidos em andamento -_ \"on the fly\", que significa 'while in motion or progress')_. Os parâmetros para a compressão são determinados pelos keywords arguments **zlib, complevel e shuffle** do método <code>createVariable</code>. Para ativar a compressão, ajuste **<code>zlib=True</code>**. A keyword **<code>complevel</code>** regula a velocidade de compressão (sendo 1 a mais rápida, porém com menor taxa de compressão, 9 sendo a mais lenta porém a mais eficiente). <code>complevel</code> padrão é 4. Ao ajustar **<code>shuffle=False</code>** irá desativar o filtro shuffle do HDF5 que desfaz a interligação de um bloco de dados antes da compressão ao reorganizar os bytes. O shuffle filter pode melhorar significativamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
