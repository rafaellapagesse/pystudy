{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python #\n",
    "\n",
    "## - Pacote NETCDF4 - ##\n",
    "\n",
    "### 0) Referências: ###\n",
    "- http://unidata.github.io/netcdf4-python/\n",
    "- http://unidata.github.io/netcdf4-python/#section1\n",
    "- http://unidata.github.io/netcdf4-python/#netCDF4.Dataset\n",
    "- https://netcdf4-python.googlecode.com/svn/trunk/docs/netCDF4-module.html\n",
    "\n",
    "\n",
    "É uma biblioteca do Python com a qual é possível criar, ler e alterar arquivos no formato netcdf. \n",
    "\n",
    "Pacotes Requeridos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**%matplorlib inline** , serve para mostrar logo após a célula de código, o resultado gerado a partir dela.\n",
    "### 1) Criando / Abrindo / Fechando um arquivo netCDF: ###\n",
    "\n",
    "   No pacote netCDF4 existe o construtor (classe) chamado **Dataset**. Ele é utilizado para abrir, ler e alterar arquivos. O Dataset de um arquivo netCDF contém informações em dimensões, variáveis, grupos e atributos. Juntos eles descrevem o significado dos dados e as relações entre os dados armazenados no arquivo netCDF. Arquivos netCDF vêm em 5 formatos; **NETCDF3_CLASSIC, NETCDF3_64BIT_OFFSET, NETCDF3_64BIT_DATA, NETCDF4_CLASSIC,** e **NETCDF4**.   \n",
    "   O modulo netCDF4 pode ler e alterar arquivos em qualquer um desses formatos. Quando criar um novo arquivo, o formato pode ser especificado usando a keyword **format** do Dataset. O formato padrão é o NETCDF4. Para ver qual é o formato de um dado arquivo, você pode usar o atributo __data_model__. Para fechar o arquivo netCDF, use o método close do Dataset.\n",
    "   \n",
    "   Segue um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arquivo = nc.Dataset(\"brleste_oc_20160303.nc\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF3_CLASSIC\n"
     ]
    }
   ],
   "source": [
    "print(arquivo.data_model)\n",
    "arquivo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que por causa da linha '<code> arquivo.close()</code>', quando essa célula for rodada novamente ocorrerá um erro e será necessário abrir novamente o arquivo pela célula acima para então conseguir o formato do netCDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Keywords do Dataset - ####\n",
    "def __init__(\tself, filename, mode=\"r\", clobber=True, diskless=False, persist=False, weakref=False, format='NETCDF4')\n",
    "\n",
    "Analisando item a item, temos que:\n",
    "\n",
    " 1. **filename**: nome do arquivo que contém o Dataset.\n",
    " \n",
    " 2. **mode**: é o modo de acesso, que pode ser: \n",
    "\n",
    " **r** : significa somente ler. Nenhum dado pode ser alterado.\n",
    " \n",
    " **w** : significa _write_ , escrever. Ele cria um novo arquivo e o arquivo com o mesmo nome é deletado.\n",
    " \n",
    " **a** ou **r+** : significa _append_; O arquivo existente é aberto para ser lido e alterado.\n",
    "  \n",
    " 3. **clobber**: Se estiver **True**(default), ao abrir um arquivo com o modo 'w' irá sobrepujar um arquivo existente com o mesmo nome. Caso esteja **False**, uma exceção será se o arquivo com o mesmo nome existir.\n",
    " \n",
    " _clobber definition (eng): to defeat someone very easily in a way that is embarrassing for the team that loses._ \n",
    "  \n",
    " 5. **diskless**: caso **\"True\"**, cria um arquivo na memória ao invés do disco rígido.\n",
    "  \n",
    " 6. **persist**: se **\"diskless=True\"**, mantém o arquivo no disco quando ele é fechado. (default **False**)\n",
    "\n",
    " 4. **format**: é o formato do arquivo netCDF( um deles: 'NETCDF4', 'NETCDF4_CLASSIC', 'NETCDF3_CLASSIC', 'NETCDF3_64BIT_OFFSET' ou 'NETCDF3_64BIT_DATA'). Só é relevante quando estiver no modo \"**w**\", caso contrário, o formato é automaticamente detectado.\n",
    "  \n",
    " 7. **keepweakref**: if True, child Dimension and Variable instances will keep weak references to the parent Dataset or Group object. Default is False, which means strong references will be kept. Having Dimension and Variable instances keep a strong reference to the parent Dataset instance, which in turn keeps a reference to child Dimension and Variable instances, creates circular references. Circular references complicate garbage collection, which may mean increased memory usage for programs that create may Dataset instances with lots of Variables. Setting keepweakref=True allows Dataset instances to be garbage collected as soon as they go out of scope, potential reducing memory usage. However, in most cases this is not desirable, since the associated Variable instances may still be needed, but are rendered unusable when the parent Dataset instance is garbage collected.\n",
    " \n",
    " #### - Variáveis do Dataset -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **data_model**: describes the netCDF data model version, one of NETCDF3_CLASSIC, NETCDF4, NETCDF4_CLASSIC, NETCDF3_64BIT_OFFSET or NETCDF3_64BIT_DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF3_CLASSIC\n"
     ]
    }
   ],
   "source": [
    "print (arquivo.data_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **dimensions**: The dimensions dictionary maps the names of dimensions defined for the Group or Dataset to instances of the Dimension class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('time', <class 'netCDF4._netCDF4.Dimension'>: name = 'time', size = 1\n",
      "), ('NbLatitudes', <class 'netCDF4._netCDF4.Dimension'>: name = 'NbLatitudes', size = 276\n",
      "), ('NbLongitudes', <class 'netCDF4._netCDF4.Dimension'>: name = 'NbLongitudes', size = 301\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print (arquivo.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **variables**: The variables dictionary maps the names of variables defined for this Dataset or Group to instances of the Variable class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('time', <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 time(time)\n",
      "    axis: T\n",
      "    calendar: gregorian\n",
      "    units: hours since 1950-01-01 00:00:00.0\n",
      "    long_name: Time (hours since 1950-01-01)\n",
      "    standard_name: time\n",
      "    _CoordinateAxisType: Time\n",
      "unlimited dimensions: \n",
      "current shape = (1,)\n",
      "filling off\n",
      "), ('NbLatitudes', <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 NbLatitudes(NbLatitudes)\n",
      "    _FillValue: 1.84467440737e+19\n",
      "    long_name: latitude\n",
      "    units: degrees_north\n",
      "    standard_name: latitude\n",
      "    _CoordinateAxisType: Lat\n",
      "    axis: Y\n",
      "unlimited dimensions: \n",
      "current shape = (276,)\n",
      "filling off\n",
      "), ('NbLongitudes', <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 NbLongitudes(NbLongitudes)\n",
      "    _FillValue: 1.84467440737e+19\n",
      "    long_name: longitude\n",
      "    units: degrees_east\n",
      "    standard_name: longitude\n",
      "    _CoordinateAxisType: Lon\n",
      "    axis: X\n",
      "unlimited dimensions: \n",
      "current shape = (301,)\n",
      "filling off\n",
      "), ('Grid_0001', <class 'netCDF4._netCDF4.Variable'>\n",
      "int8 Grid_0001(time, NbLongitudes, NbLatitudes)\n",
      "    _CoordinateAxes: time NbLongitudes NbLatitudes \n",
      "    _FillValue: 127\n",
      "    scale_factor: 0.0119048\n",
      "    long_name: oa_plankton\n",
      "    units: mg/m3\n",
      "    unit_long: mg/m3\n",
      "    standard_name: chlorophyll_concentration_in_sea_water\n",
      "    source: objective_analysis\n",
      "unlimited dimensions: \n",
      "current shape = (1, 301, 276)\n",
      "filling off\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print (arquivo.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **groups**: The groups dictionary maps the names of groups created for this Dataset or Group to instances of the Group class (the Dataset class is simply a special case of the Group class which describes the root group in the netCDF4 file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "print (arquivo.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **vltypes**: The vltypes dictionary maps the names of variable-length types defined for the Group or Dataset to instances of the VLType class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "print (arquivo.vltypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **path**: path shows the location of the Group in the Dataset in a unix directory format (the names of groups in the hierarchy separated by backslashes). A Dataset instance is the root group, so the path is simply '/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "print (arquivo.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **parent**: parent is a reference to the parent Group instance. None for the root group or Dataset instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print (arquivo.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **disk_format**: disk_format describes the underlying file format, one of NETCDF3, HDF5, HDF4, PNETCDF, DAP2, DAP4 or UNDEFINED. Only available if using netcdf C library version >= 4.3.1, otherwise will always return UNDEFINED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF3\n"
     ]
    }
   ],
   "source": [
    "print(arquivo.disk_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **enumtypes**: The enumtypes dictionary maps the names of Enum types defined for the Group or Dataset to instances of the EnumType class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "print (arquivo.enumtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **cmptypes**: The cmptypes dictionary maps the names of compound types defined for the Group or Dataset to instances of the CompoundType class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "print(arquivo.cmptypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2) Grupos em um arquivo netCDF ###\n",
    "\n",
    "Os grupos em um netCDF (na versão 4) funcionam como diretórios no Sistema Operacional (SO). Os grupos servem como containers para variáveis, dimensões e atributos, assim como outros grupos. O Dataset cria um grupo especial, chamado 'root group', que é similar ao diretório raiz em um sistema operacional. \n",
    "\n",
    "Para criar um grupo, use o método <code> createGroup </code> do Dataset. O <code> createGroup </code> requer um único argumento, uma  string do python contendo o nome do novo grupo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootgrp = nc.Dataset(\"teste.nc\", \"w\", format='NETCDF4')\n",
    "rootgrp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootgrp = nc.Dataset(\"teste.nc\",\"a\")\n",
    "fcastgrp = rootgrp.createGroup(\"forecasts\")\n",
    "analgrp = rootgrp.createGroup(\"analyses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('forecasts', <class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "), ('analyses', <class 'netCDF4._netCDF4.Group'>\n",
      "group /analyses:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupos podem existir dentro de grupos em um Dataset, como pastas existem dentro de pastas. Cada instância tem um atributo **<code>groups</code>** contendo todos os grupos que se encontram dentro daquele grupo.\n",
    "\n",
    "Cada instância de um grupo também tem um atributo **<code> path </code>** que contém uma espécie de path de um diretório unix para esse grupo. \n",
    "\n",
    "Observe o exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('forecasts', <class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: model1, model2\n",
      "), ('analyses', <class 'netCDF4._netCDF4.Group'>\n",
      "group /analyses:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "fcastgrp1 = rootgrp.createGroup(\"/forecasts/model1\")\n",
    "fcastgrp2 = rootgrp.createGroup(\"/forecasts/model2\")\n",
    "print(rootgrp.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** Obs.: **Note que o atributo <code> groups </code> agora contém os crupos criados dentro de /forecast.     \n",
    "<code>      \n",
    "        OrderedDict([('forecasts', <class 'netCDF4._netCDF4.Group'>\n",
    "        group /forecasts:\n",
    "            dimensions(sizes): \n",
    "            variables(dimensions): \n",
    "            groups: model1, model2)\n",
    "        \n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootgrp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Dimensões em um arquivo netCDF ###\n",
    "\n",
    "netCDF define os tamanhos de todas as variáveis em termos de dimensões, então antes de qualquer variável ser criada as dimensões que elas usam devem ser  criadas antes. Um caso especial, pouco usado na prática, é o de uma variável escalar, que não tem dimensão.\n",
    "\n",
    "Uma dimensão é criada usando o método <code> createDimension</code> do Dataset ou Grupo. Uma string do Python é usada para atribuir o nome da dimensão e um numero inteiro é usado para atribuir o tamanho. Para criar uma dimensão ilimitada (uma dimensão que possa ser adicionada - _appended to_), o valor do tamanho é configurado como <code> None </code> ou <code> 0 </code>.\n",
    "\n",
    "Neste exemplo, tanto as dimensões **<code>time</code>** e **<code>level</code>** são ilimitadas. Ter mais de uma dimensão ilimitada é uma característica do netCDF4, nos arquivos netCDF3 só poderia haver uma, e ela deveria ser a primeira dimensão da variável.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootgrp = nc.Dataset(\"teste.nc\",\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level = rootgrp.createDimension(\"level\", None)\n",
    "time = rootgrp.createDimension(\"time\",None)\n",
    "lat = rootgrp.createDimension(\"latitude\", 73)\n",
    "lon = rootgrp.createDimension(\"longitude\",144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as dimensões foram armazenadas em um dicionário python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('level', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\n",
      "), ('time', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      "), ('latitude', <class 'netCDF4._netCDF4.Dimension'>: name = 'latitude', size = 73\n",
      "), ('longitude', <class 'netCDF4._netCDF4.Dimension'>: name = 'longitude', size = 144\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a função <code>len</code> com uma dimensão retorna o tamanho atual daquela dimensão. O método <code>isunlimited</code> de uma dimensão pode ser usado para determinar se a dimensão é ilimitada, ou _appendable_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "print(len(lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(lat.isunlimited())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(time.isunlimited())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Printar\" o <code>Dimension object</code> (dimobj) fornece informação resumida, incluindo o nome e o tamanho da dimensão, além de informar se são ilimitadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'latitude', size = 73\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'longitude', size = 144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dimobj in rootgrp.dimensions.values():\n",
    "    print(dimobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nome de Dimensões pode ser alterado usando o método **<code>netCDF4.Datatset.renameDimension</code>** de um Dataset ou Group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Variáveis em um arquivo netCDF ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
